import numpy as np
import tensorflow as tf
import torch as tr
from torch import nn


def rotate(x, y, z):
    """
    Make a 3-D rotation matrix to rotate [x] degree around x-axis, [y]
    degree around y-axis, and [z] degree around z-axis.
    Args:
        x   float   radius rotation around x-axis
        y   float   radius rotation around y-axis
        z   float   radius rotation around z-axis
    Returns:
        R_x(x) * R_y(y) * R_z(z)
    """
    R_x = tr.stack([
        tr.tensor([1., 0., 0.]),
        tr.stack([tr.tensor(0.), tr.cos(x), -tr.sin(x)]),
        tr.stack([tr.tensor(0.), tr.sin(x), tr.cos(x)])
    ])

    R_y = tr.stack([
        tr.stack([tr.cos(y), tr.tensor(0.), tr.sin(y)]),
        tr.tensor([0., 1., 0.]),
        tr.stack([-tr.sin(y), tr.tensor(0.), tr.cos(y)])
    ])

    R_z = tr.stack([
        tr.stack([tr.cos(z), -tr.sin(z), tr.tensor(0.)]),
        tr.stack([tr.sin(z), tr.cos(z), tr.tensor(0.)]),
        tr.tensor([0., 0., 1.])
    ])

    # Note: in tensorflow, we use x*R, but the ground truth is generated by R*x in numpy.
    # Since in numpy, y = R*x = R_z*R_x*R_y*x, so we want y = x*R = x*R_y*R_x*R_z = x*R
    return tr.mm(R_y, tr.mm(R_x, R_z))


def rotate_grid(vg, vp, size=32, rotation_axis='X', viewpoints=10,
                rx_range=[-20., 40.], ry_range=[0., 360.], rz_range=[0., 0.],
                verbose=0):
    vg = vg.view(vg.shape[0], size, size, size)
    nx, ny, nz = vg.shape[1:4]
    x_range = tr.arange(-size / 2, size / 2, 1).float()
    y_range = tr.arange(-size / 2, size / 2, 1).float()
    z_range = tr.arange(-size / 2, size / 2, 1).float()
    pos_x, pos_y, pos_z = tr.meshgrid([x_range, y_range, z_range])
    grid = [
        pos_y.contiguous().view(-1),
        pos_x.contiguous().view(-1),
        pos_z.contiguous().view(-1)
    ]
    grid = tr.stack(grid, dim=1)

    output_vg = []
    vgs = list(vg)
    view_points = list(vp)
    assert len(vgs) == len(view_points)

    batch = 0
    for i, (curr_vg, curr_z) in enumerate(zip(vgs, view_points)):
        batch += 1

        # Add domain specific knowledges to it
        if rotation_axis == 'X':
            rotation_angle = tr.floor((curr_z + 1.) * viewpoints / 2.) * 2 * np.pi / viewpoints
            rotation = rotate(rotation_angle, 0., 0.)

        elif rotation_axis == 'Y':
            rotation_angle = tr.floor((curr_z + 1.) * viewpoints / 2.) * 2 * np.pi / viewpoints
            rotation = rotate(0., rotation_angle, 0.)

        elif rotation_axis == 'Z':
            rotation_angle = tr.floor((curr_z + 1.) * viewpoints / 2.) * 2 * np.pi / viewpoints
            rotation = rotate(0., 0., rotation_angle)

        elif rotation_axis == 'XYZ':
            rx_angle = curr_z[0] / 180. * np.pi
            ry_angle = curr_z[1] / 180. * np.pi
            rz_angle = curr_z[2] / 180. * np.pi
            rotation = rotate(rx_angle, ry_angle, rz_angle)

        else:
            raise Exception("Invalide rotation axis: %s" % rotation_axis)
        target_grid = tr.mm(grid.float(), rotation).long()
        x_oob = (target_grid[:, 0] < (-nx / 2)) | (target_grid[:, 0] >= nx / 2)
        y_oob = (target_grid[:, 1] < (-ny / 2)) | (target_grid[:, 1] >= ny / 2)
        z_oob = (target_grid[:, 2] < (-nz / 2)) | (target_grid[:, 2] >= nz / 2)

        xyz_inbound = (~(x_oob | y_oob | z_oob)).float()

        idx_lower_bound = ((-size / 2.0) * tr.ones(target_grid.shape).long())
        idx_upper_bound = ((size / 2.0 - 1) * tr.ones(target_grid.shape).long())

        target_grid_inbound = tr.max(idx_lower_bound, target_grid)
        target_grid_inbound = tr.min(idx_upper_bound, target_grid_inbound)
        target_grid_inbound = (size / 2) * tr.ones(target_grid.shape).long() + target_grid_inbound.long()

        # gathered = curr_vg.masked_select(target_grid_inbound)
        idx1, idx2, idx3 = target_grid_inbound.chunk(3, dim=1)
        gathered = curr_vg[idx1, idx2, idx3].squeeze()

        if verbose > 0:
            tf.summary.histogram("grid_%d_x" % i, target_grid_inbound[:, 0])
            tf.summary.histogram("grid_%d_y" % i, target_grid_inbound[:, 1])
            tf.summary.histogram("grid_%d_z" % i, target_grid_inbound[:, 2])
            tf.summary.histogram("gathered_%d" % i, gathered)

        masked = gathered * xyz_inbound
        output_vg.append(masked.view(nx, ny, nz))
    rotated = tr.stack(output_vg)
    return rotated


def projection_orthographic(rotated, size=32, temperature=1.):
    output_imgs = 1 - tr.exp(-tr.sum(rotated, dim=3) * temperature)
    output_imgs = output_imgs.view(rotated.shape[0], 1, size, size)
    return output_imgs


def orthographic_coor(n=32, out_size=32):
    r = out_size / float(n)
    return [[np.array([np.array([int(x / r), int(y / r), z]) \
                       for z in range(out_size)]) \
             for y in range(out_size)] \
            for x in range(out_size)]


def np_pers_coor(vox, s=1, d=1, f=1, out_size=32):
    """
    Args:
        [vox]       (np.array [n]x[n]x[n])          Voxel grid
        [s]         (float)    The size of each voxel
        [d]         (float)    The distance from camera center to the first grid
        [p]         (float)    The size of a pixel in the projection plane
        [f]         (float)    Focal length.
        [out_size]  (int)      The size of the output image.
    Assumption:
        1. assuming that projection plane is always in z=1
    Rets:
        [ret]    (list(list(list([x,y,z]))))
                 ret[x][y] -> [(x_1,y_1,z_1), ..., (x_n,y_n,z_n)]
    """
    n = vox.shape[0]
    p = n * s / float(d) / float(out_size)
    pp_lower_x = (-n / 2) * s / float(d)
    pp_lower_y = (-n / 2) * s / float(d)
    print("P:%.5f" % p)
    ret = [[list() for _ in range(out_size)] for _ in range(out_size)]
    reverse_mapping = [[[list() for _ in range(n)] for _ in range(n)] for _ in range(n)]
    for l in range(n):  # l is the depth in the voxel level
        z = d + l * s
        for x in range(n):
            for y in range(n):
                x_c = x * s - n / 2
                y_c = y * s - n / 2
                lower_x = int(np.floor((x_c / float(z) - pp_lower_x) / float(p)))
                upper_x = int(np.floor(((x_c + s) / float(z) - pp_lower_x) / float(p)))
                lower_y = int(np.floor((y_c / float(z) - pp_lower_y) / float(p)))
                upper_y = int(np.floor(((y_c + s) / float(z) - pp_lower_y) / float(p)))
                has_skip = True
                for x_p in range(lower_x, upper_x):
                    for y_p in range(lower_y, upper_y):
                        has_skip = False
                        ret[x_p][y_p].append(np.array([x, y, l]))
                        reverse_mapping[x][y][l].append(np.array([x_p, y_p]))
                if has_skip:
                    ret[lower_x][lower_y].append(np.array([x, y, l]))
    for x_p in range(len(ret)):
        for y_p in range(len(ret[x_p])):
            ret[x_p][y_p] = np.array(ret[x_p][y_p])
    return ret, reverse_mapping


def perspective_coor(n=32, s=1, d=1, f=1, out_size=32):
    """
    Args:
        [n]         (int)      Size of the voxel grid
        [s]         (float)    The size of each voxel
        [d]         (float)    The distance from camera center to the first grid
        [p]         (float)    The size of a pixel in the projection plane
        [f]         (float)    Focal length.
        [out_size]  (int)      The size of the output image.
    Assumption:
        1. assuming that projection plane is always in z=1
    Rets:
        [ret]    (list(list(list([x,y,z]))))
                 ret[x][y] -> [(x_1,y_1,z_1), ..., (x_n,y_n,z_n)]
    """
    ret, _ = np_pers_coor(np.zeros((n, n, n)), s=s, d=d, f=f, out_size=out_size)
    return ret


def coor_to_coormask(coor_array, batch_size):
    n = len(coor_array)
    max_len = max([len(coor_array[i][j]) for i in range(n) for j in range(n)])
    coor = np.zeros((batch_size, n, n, max_len, 4))
    mask = np.zeros((batch_size, n, n, max_len))
    for b in range(batch_size):
        for i in range(n):
            for j in range(n):
                for k, c in enumerate(coor_array[i][j]):
                    coor[b, i, j, k, :] = np.array([b, c[0], c[1], c[2]])
                    mask[b, i, j, k] = 1
    return coor, mask


# NOTE: this works reasonably well, permutation too sow :(
def project_perspective(vg, coor_array, batch_size=128, size=32, temperature=1.,
                        projector_pooling='exp', verbose=0):
    """
    Args:
        [vg]    (np.array [b]x[n]x[n]x[n])      Voxel grid
        [coor]  (list(list(list([x,y,z]))))     The coordinate of the perspective projection
    Rets:
        [img]   (np.array [b]x[n]x[n])              Projected image
    """
    vg_t = vg.permute([1, 2, 3, 0])

    coor, mask = coor_to_coormask(coor_array, 1)
    mask_batch = mask.astype(np.int)[0, ..., np.newaxis]
    coor_batch = coor.astype(np.int)[0, ..., 1:]

    coor_batch = tr.tensor(coor_batch)
    idx = coor_batch.chunk(125, dim=3)
    gathered = vg_t[idx].squeeze()

    gathered = gathered * tr.tensor(mask_batch).float()

    gathered = gathered.permute([3, 0, 1, 2])

    if projector_pooling == 'exp':
        pooled = 1 - tr.exp(-tr.sum(gathered, dim=-1) * temperature)
    elif projector_pooling == 'max':
        pooled = tr.max(gathered, dim=-1)
    elif projector_pooling == 'avg':
        pooled = tr.mean(gathered, dim=-1)
    else:
        raise Exception("Invalid pooling type : %s" % projector_pooling)

    return pooled


# NOTE: this works reasonably well, fast, but graph is large
def project_perspective_fast(
        vg, mask_batch, coor_batch, batch_size=128, size=32, temperature=1.,
        projector_pooling='exp', verbose=0
):
    """
    Args:
        [vg]    (np.array [b]x[n]x[n]x[n])      Voxel grid
        [coor]  (list(list(list([x,y,z]))))     The coordinate of the perspective projection
    Rets:
        [img]   (np.array [b]x[n]x[n])              Projected image
    """
    idx = coor_batch.chunk(125, dim=3)
    gathered = vg[idx].squeeze()
    gathered = gathered * tr.tensor(mask_batch).float()

    if projector_pooling == 'exp':
        pooled = 1 - tr.exp(-tr.sum(gathered, axis=-1) * temperature)
    elif projector_pooling == 'max':
        pooled = tr.max(gathered, axis=-1)
    elif projector_pooling == 'avg':
        pooled = tr.mean(gathered, axis=-1)
    else:
        raise Exception("Invalid pooling type : %s" % projector_pooling)

    return pooled


class Projector(nn.Module):

    def __init__(self, config, verbose=False):
        self.vox_size = config.vox_size
        self.rotation_axis = config.rotation_axis
        self.viewpoints = config.viewpoints
        self.rx_range = config.rx_range
        self.ry_range = config.ry_range
        self.rz_range = config.rz_range
        self.projection_typ = config.projection_typ
        self.batch_size = config.batch_size
        self.resolution = config.resolution
        self.projector_pooling = config.pooling_typ
        self.temperature = config.projection_temperature
        self.verbose = verbose
        self.distance = config.distance

        if self.projection_typ == 'orthographic':
            self.coor = orthographic_coor(n=self.vox_size, out_size=self.resolution)
        elif self.projection_typ == 'perspective':
            self.coor = perspective_coor(n=self.vox_size, s=1, d=self.distance, out_size=self.resolution)
        elif self.projection_typ == 'perspective_fast':
            self.coor = perspective_coor(n=self.vox_size, s=1, d=self.distance, out_size=self.resolution)
            coor, mask = coor_to_coormask(self.coor, self.batch_size)
            self.mask_batch = tr.tensor(mask.astype(np.int))
            self.coor_batch = tr.tensor(coor.astype(np.int))

            print("Maskbatch:" + str(self.mask_batch.shape))
            print("Coorbatch:" + str(self.coor_batch.shape))
        else:
            self.coor = None
        super(Projector, self).__init__()

        print("Building projection generator...")
        print("\tRotation axis=%s..." % self.rotation_axis)
        print("\tNumber of viewpoints=%s..." % self.viewpoints)
        print("\tBatch size:%s" % self.batch_size)
        print("\tProjection Tyoe:%s" % self.projection_typ)
        print("\tTemperature:%s" % self.temperature)
        print("\tResolution:%s" % self.resolution)
        print("\tPooling type:%s" % self.projector_pooling)

    def forward(self, vox, vp):

        rotated = rotate_grid(
            vox, vp, rotation_axis=self.rotation_axis, viewpoints=self.viewpoints,
            rx_range=self.rx_range, ry_range=self.ry_range, rz_range=self.rz_range
        )

        if self.projection_typ in ['orthographic', 'perspective']:
            p = project_perspective(
                rotated, self.coor, batch_size=self.batch_size,
                size=self.resolution, projector_pooling=self.projector_pooling,
                temperature=self.temperature, verbose=0)
            p = p[:, None]
        elif self.projection_typ == 'perspective_fast':
            p = project_perspective_fast(
                rotated, self.mask_batch, self.coor_batch, batch_size=self.batch_size,
                size=self.resolution, projector_pooling=self.projector_pooling,
                temperature=self.temperature, verbose=0)
            p = tf.expand_dims(p, -1)
        elif self.projection_typ == 'orthographic_fast':
            p = projection_orthographic(
                rotated, size=self.vox_size, temperature=self.temperature)
        else:
            raise Exception("Invalid projector type:%s" % self.projection_typ)

        return p
